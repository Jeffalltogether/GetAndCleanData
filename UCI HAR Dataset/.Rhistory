?select
?rm.na
?is.na
?na.rm
T <-
idaho %<%
select(ACR, AGS,) %>%
filter(ACR > & AGS > 6) %>%
print
DT <-
idaho %<%
select(ACR, AGS,) %>%
filter(ACR > & AGS > 6) %>%
print
DT <-
idaho %<%
select(ACR, AGS,)
DT <-
idaho %>%
select(ACR, AGS,) %>%
filter(ACR > & AGS > 6) %>%
print
DT <-
idaho %>%
select(ACR, AGS,)
DT <-
idaho %>%
select(ACR, AGS,) %>%
filter(ACR >= 3& AGS >= 6) %>%
print
# which(agricultureLogical) What are the first 3 values that result?
DT <-
idaho %>%
select(ACR, AGS) %>%
filter(ACR >= 3& AGS >= 6) %>%
print
idaho[id := 1:length(idaho)]
class(idaho)
agricultureLogical <-
idaho %>%
mutate(id = 1:length(idaho)) %>%
select(id, ACR, AGS) %>%
filter(ACR >= 3& AGS >= 6) %>%
print
nrow(idaho)
agricultureLogical <-
idaho %>%
mutate(id = 1:nrow(idaho)) %>%
select(id, ACR, AGS) %>%
filter(ACR >= 3& AGS >= 6) %>%
print
install.packages("jpeg")
?read.jpeg
?library("jpeg")
?jpeg
fileUrl <- https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg
# Use the parameter native=TRUE. What are the 30th and 80th quantiles of the resulting data?
library(jpeg)
readJPEG(fileUrl, native=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
# Use the parameter native=TRUE. What are the 30th and 80th quantiles of the resulting data?
library(jpeg)
jpeg <- readJPEG(fileUrl, native=TRUE)
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "./data/pic.jpg") #curl is necessary for MAC users getting data from https
list.files("./data") # sort of like the ls() command, shows the files in the directory "./data"
dateDownloaded <- date()
dateDownloaded
# Use the parameter native=TRUE. What are the 30th and 80th quantiles of the resulting data?
library(jpeg)
jpeg <- readJPEG("./data/pic.jpg", native=TRUE)
30th <- quantile(jpeg, 30)
30th <- quantile(jpeg, probs = 30)
parta <- quantile(jpeg, probs = 30)
head(jpeg)
dim(jpeg)
class(jpeg)
jpeg <- as.data.table(jpeg)
jpeg <- as.matrix(jpeg)
parta <- quantile(jpeg, probs = 30)
parta <- quantile(jpeg, probs = 0.30)
partb <- quantile(jpeg, probs = 0.80)
jpeg <- readJPEG("./data/pic.jpg", native=TRUE)
parta <- quantile(jpeg, probs = 0.30)
partb <- quantile(jpeg, probs = 0.80)
?melt
library(reshape2)
jpeg <- melt(jpeg)
jpeg <- melt(as.matrix(jpeg))
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
download.file(fileUrl, destfile = "./data/fgdp.csv") #curl is necessary for MAC users getting data from https
list.files("./data") # sort of like the ls() command, shows the files in the directory "./data"
fgdp <- read.csv("./data/fgdp.csv")
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "./data/fgdp.csv") #curl is necessary for MAC users getting data from https
download.file(fileUrl2, destfile = "./data/fedstats.csv") #curl is necessary for MAC users getting data from https
list.files("./data") # sort of like the ls() command, shows the files in the directory "./data"
fgdp <- read.csv("./data/fgdp.csv")
fedstats <- read.csv("./data/fedstats.csv")
str(fgdp)
head(fgdp)
?read.csv
fgdp <- read.csv("./data/fgdp.csv", skip = 4)
head(fgdp)
head(fedstats)
?match
match(fgdp$X, fedstats$CountryCode)
x <- select(fgdp$X, fedstats$CountryCode)
x <- data.frame(fgdp$X, fedstats$CountryCode)
x <- match(fgdp$X, fedstats$CountryCode)
is.na(x)
y <- sum(is.na(x))
y <- sum(!is.na(x))
head(fgdp)
fgdp <- read.csv("./data/fgdp.csv")
head(fgdp)
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
?read.csv
fgdp <- read.csv("./data/fgdp.csv", colnames = names)
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9")
fgdp <- read.csv("./data/fgdp.csv", colnames = names)
names
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
fgdp <- read.csv("./data/fgdp.csv", colnames = names)
fgdp <- read.csv("./data/fgdp.csv", col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "CountryCode")
head(x)
dim(x)
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode")
x
head(x)
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode", all = TRUE)
sum(is.na(x$CountryCode))
fgdp <- read.csv("./data/fgdp.csv")
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "X", by.y ="CountryCode", all = TRUE)
sum(is.na(x$CountryCode))
sum(is.na(x$X))
head(x)
fgdp <- read.csv("./data/fgdp.csv", skip = 4)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "X", by.y ="CountryCode", all = TRUE)
head(x)
fgdp <- read.csv("./data/fgdp.csv", skip = 4, col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "X", by.y ="CountryCode", all = TRUE)
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode", all = TRUE)
head(x)
# Question 3
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "./data/fgdp.csv") #curl is necessary for MAC users getting data from https
download.file(fileUrl2, destfile = "./data/fedstats.csv") #curl is necessary for MAC users getting data from https
list.files("./data") # sort of like the ls() command, shows the files in the directory "./data"
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
fgdp <- read.csv("./data/fgdp.csv", skip = 4, col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode", all = TRUE)
# Match the data based on the country shortcode. How many of the IDs match?
head(x)
fileUrl1 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv"
fileUrl2 <- "https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv"
download.file(fileUrl1, destfile = "./data/fgdp.csv") #curl is necessary for MAC users getting data from https
download.file(fileUrl2, destfile = "./data/fedstats.csv") #curl is necessary for MAC users getting data from https
list.files("./data") # sort of like the ls() command, shows the files in the directory "./data"
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
fgdp <- read.csv("./data/fgdp.csv", skip = 4, col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode", all = TRUE)
# Match the data based on the country shortcode.
head(x)
fgdp
head(fgdp)
head(fedstats)
names <- c("CountryCode1", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
fgdp <- read.csv("./data/fgdp.csv", skip = 4, col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "CountryCode1", by.y ="CountryCode", all = TRUE)
head(x)
x <- merge(fgdp, fedstats, by.x = "CountryCode1", by.y ="CountryCode")
head(x)
select(x$CountryCode1)
x$CountryCode1
x$CountryCode
x$CountryCode1 == x$CountryCode
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
fgdp <- read.csv("./data/fgdp.csv", skip = 4, col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
y <- join(fgdp, fedstats)
head(y)
sum(is.na(y$CountryCode))
unique(y$CountryCode)
fgdp$CountryCode == fedstats$CountryCode
y$CountryCode
?join
y <- anit_join(fgdp, fedstats)
y <- anti_join(fgdp, fedstats)
x
head(x)
head(y)
head(y)
sort(y, desc)
sort(y, CountryCode = desc)
arrange(y, CountryCode = desc)
?arrange
arrange(y, CountryCode)
tail(y, 13)
y <- y[,!is.na(y)]
y <- y[,!is.na()]
x <- is.na(x)
x
tail(y$CountryCode[!is.na(y$CountryCode)])
tail(y$CountryCode[!is.na(y$CountryCode)], 13)
col.names(fedstats)
colnames(fedstats)
fgdp <- read.csv("./data/fgdp.csv")
fgdp
View(fedstats)
?read.csv
fgdp <- read.csv("./data/fgdp.csv", skip = 4, nrows = 194-4)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode")
y <- join(fgdp, fedstats)
y <- join(fgdp, fedstats, by = CountryCode)
y <- join(fgdp, fedstats, by = "CountryCode")
?join
y <- join(fgdp, fedstats)
y
fedstats
y <- join(fgdp, fedstats, by = CountryCode)
fedstats$CountryCode
fgdp$CountryCode
names <- c("CountryCode", "GDP_Ranking", "X3", "Country", "$M", "X6", "X7", "X8", "X9", "X10")
fgdp <- read.csv("./data/fgdp.csv", skip = 4, nrows = 194-4, col.names = names)
fedstats <- read.csv("./data/fedstats.csv")
x <- merge(fgdp, fedstats, by.x = "CountryCode", by.y ="CountryCode")
y <- join(fgdp, fedstats, by = CountryCode)
fgdp$CountryCode
y <- join(fgdp, fedstats, by = "CountryCode")
head(nonODEC)
head(nonOECD)
nonOECD <- filter(y, Income.Group == "High income: nonOECD")
OECD <- filter(y, Income.Group == "High income: OECD")
head(nonOECD)
colnames(nonOEDC)
col.names(nonOEDC)
names(nonOEDC)
nonOEDC$GDP_Ranking
nonRank <- mean(nonOEDC$GDP_Ranking)
nonOECD <- filter(y, Income.Group == "High income: nonOECD")
nonRank <- mean(nonOECD$GDP_Ranking)
OECD <- filter(y, Income.Group == "High income: OECD")
Rank <- mean(OECD$GDP_Ranking)
quantiles <- quantile(y$GDP_Rank, probs = seq(0.2, 1.0, 0.2) )
quantiles
head(y)
y$GDP_Rank <= quantiles
quantiles[,1]
quantiles[1]
quantiles <- quantile(y$GDP_Rank, probs = seq(0.2, 1.0, 0.2) )
DT <-
y %>%
select(Short.Name, Income.Group, GDP_Rank) %>%
mutate(quantile = 1) %>%
print
quantiles <- quantile(y$GDP_Ranking, probs = seq(0.2, 1.0, 0.2) )
DT <-
y %>%
select(Short.Name, Income.Group, GDP_Ranking) %>%
mutate(quantile = 1) %>%
print
y$GDP_Ranking[1]
y$GDP_Ranking[2]
y$GDP_Ranking[5]
quantiles
for (i in 1:length(y)){
if (y$GDP_Ranking[i] >= quantiles[1]){
y$quantile[i] = 2
}
if (y$GDP_Ranking[i] >= quantiles[2]){
y$quantile[i] = 3
}
if (y$GDP_Ranking[i] >= quantiles[3]){
y$quantile[i] = 4
}
if (y$GDP_Ranking[i] >= quantiles[4]){
y$quantile[i] == 5
}
if (y$GDP_Ranking[i] < quantiles[1]){
y$quantile[i] == 1
}
}
for (i in 1:nrow(y)){
if (y$GDP_Ranking[i] >= quantiles[1]){
y$quantile[i] = 2
}
if (y$GDP_Ranking[i] >= quantiles[2]){
y$quantile[i] = 3
}
if (y$GDP_Ranking[i] >= quantiles[3]){
y$quantile[i] = 4
}
if (y$GDP_Ranking[i] >= quantiles[4]){
y$quantile[i] == 5
}
if (y$GDP_Ranking[i] < quantiles[1]){
y$quantile[i] == 1
}
}
nrow(y)
for (i in 1:nrow(y)){
if (y$GDP_Ranking[i] >= quantiles[1]){
y$quantile[i] = 2
}
if (y$GDP_Ranking[i] >= quantiles[2]){
y$quantile[i] = 3
}
if (y$GDP_Ranking[i] >= quantiles[3]){
y$quantile[i] = 4
}
if (y$GDP_Ranking[i] >= quantiles[4]){
y$quantile[i] == 5
}
if (y$GDP_Ranking[i] < quantiles[1]){
y$quantile[i] == 1
}
}
DT <-
y %>%
select(Short.Name, Income.Group, GDP_Ranking) %>%
arrange(GDP_Ranking) %>%
print
DT <-
y %>%
select(Short.Name, Income.Group, GDP_Ranking) %>%
arrange(GDP_Ranking) %>%
head(y, 38)
quantiles <- quantile(y$GDP_Ranking, probs = seq(0.2, 1.0, 0.2) )
DT <-
y %>%
select(Short.Name, Income.Group, GDP_Ranking) %>%
arrange(GDP_Ranking) %>%
head(DT, 38)
DT <-
y %>%
select(Short.Name, Income.Group, GDP_Ranking) %>%
arrange(GDP_Ranking) %>%
print
quantiles
y[1:38,]
DT[1:38,]
DT2 <- DT[1:38,]
count <- sum(DT2$Income.Group == "Lower middle income")
count
1 - 125, 238,262
fileUrl <- "https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
download.file(fileUrl, destfile = "./data/pic.jpg") #curl is necessary for MAC users getting data from https
list.files("./data") # sort of like the ls() command, shows the files in the directory "./data"
# Use the parameter native=TRUE. What are the 30th and 80th quantiles of the resulting data?
library(jpeg)
library(reshape2)
jpeg <- readJPEG("./data/pic.jpg", native=TRUE)
parta <- quantile(jpeg, probs = 0.30)
partb <- quantile(jpeg, probs = 0.80)
unique(jpeg)
parta
partapartb
partb
dim(jpeg)
180*180
length(unique(jpeg))
10072*.3
arrange(unique(jpeg))
DT <- unique(jpeg)
arrange(DT)
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI HAR Dataset")
library(data.table)
## set path to the data
PHdata="C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI_HAR_Dataset/"
PHdata=file.path(getwd(),"UCI_HAR_Dataset/")
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI HAR Dataset")
#################################
## read the test dataset
#################################
subject_test <- fread(file.path(PHdata,"test/subject_test.txt"))
PHdata="C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI_HAR_Dataset/"
#PHdata=file.path(getwd(),"UCI_HAR_Dataset/")
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI HAR Dataset")
#################################
## read the test dataset
#################################
subject_test <- fread(file.path(PHdata,"test/subject_test.txt"))
setnames(subject_test,"subject")
## I couldn't use the fread function here, since it has a bug while reading datasets with many columns
PHdata="C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI_HAR_Dataset/"
PHdata=file.path(getwd(),"UCI_HAR_Dataset/")
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI HAR Dataset")
#################################
## read the test dataset
#################################
subject_test <- fread(file.path(PHdata,"test/subject_test.txt"))
setnames(subject_test,"subject")
## I couldn't use the fread function here, since it has a bug while reading datasets with many columns
x_test <- as.data.table(read.table(file=file.path(PHdata,"test/X_test.txt"),header=FALSE))
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI HAR Dataset")
#################################
## read the test dataset
#################################
subject_test <- fread("./test/subject_test.txt")
setnames(subject_test,"subject")
## I couldn't use the fread function here, since it has a bug while reading datasets with many columns
x_test <- as.data.table(read.table(file="./test/X_test.txt"),header=FALSE))
x_test <- as.data.table(read.table(file="./test/X_test.txt"),header=FALSE)
x_test <- as.data.table(read.table(file="./test/X_test.txt"))
colnames(x_test)
y_test <- fread("./test/y_test.txt")
setnames(y_test,"activity")
## read the appropriate features + name the variables with these feature names
features <- fread(file.path(PHdata,"features.txt"))
features <- fread("features.txt")
length(names(x_test))==length(features$V2)  ## lengths match
setnames(x_test,features$V2)
#################################
## read the training dataset
#################################
## totally analogous to reating the test dataset ("test" -> "train")
subject_train <- fread("./train/subject_train.txt"))
setnames(subject_train,"subject")
subject_train <- fread("./train/subject_train.txt")
setnames(subject_train,"subject")
x_train <- as.data.table(read.table(file="./train/X_train.txt"))
y_train <- fread(file.path(PHdata,"train/y_train.txt"))
y_train <- fread("./train/y_train.txt")
setnames(y_train,"activity")
features <- fread(file.path(PHdata,"features.txt"))
features <- fread("features.txt"))
features <- fread("features.txt")
length(names(x_train))==length(features$V2)  ## lengths match
setnames(x_train,features$V2)
############################################
## step 1
## merge the test and training dataset
############################################
X <- rbindlist(list(x_test, x_train))
y <- rbindlist(list(y_test, y_train))
subject <- rbindlist(list(subject_test, subject_train))
rm("x_train","y_train","subject_train","x_test","y_test","subject_test")
############################################
## step 2 + step 4
## Extract only the measurements on the mean and standard deviation for each measurement.
## Appropriately labels the data set with descriptive variable names.
############################################
ismean <- grepl("\\-mean\\(\\)\\-",names(X))           ## string contains -mean()-
isstd <- grepl("\\-std\\(\\)\\-",names(X))  	## string contains -std()-
## take only the columns/variables that contain either "-mean()-" or "-std()-" in the name
X_subset <- X[,ismean | isstd,with=FALSE]
############################################
## step 3
## Use descriptive activity names to name the activity in the data set
############################################
## read the hash table for activity labels
acttable <- fread(file.path(PHdata,"activity_labels.txt"))
setnames(acttable,c("integer.name","descriptive.name"))
acttable <- fread("activity_labels.txt")
setnames(acttable,c("integer.name","descriptive.name"))
## use this hash table to rename the y vector
setkey(acttable,integer.name)
y_descr<- acttable[y,list(activity=descriptive.name)]
## merge y,subject,X into one data.table
dt <- data.table(y_descr,subject,X_subset)
## write the results
write.table(dt,file = file.path(PHdata,"../dt.txt"), row.names = FALSE)
View(dt)
###  Getting and Cleaning Data Course Project
# Merges the training and the test sets to create one data set.
# Extracts only the measurements on the mean and standard deviation for each measurement.
# Uses descriptive activity names to name the activities in the data set
# Appropriately labels the data set with descriptive variable names.
# From the data set in step 4, creates a second, independent tidy data set with the average of each variable for each activity and each subject.
setwd("C:/Users/jeffthatcher/Cloud Drive/RRepos/GetCleanData/UCI HAR Dataset")
library(XML)
library(data.table)
library(dplyr)
library(tidyr)
## read Data
features <- read.table("./features.txt", header=FALSE, sep=" ")                                 # the list of features will be the Column Names
trainLabel <- read.table ("./train/y_train.txt", header=FALSE, sep = " ")                       # this will create the list of the Subjects ID number that will eventuall become the subjects column in the data table
train <- read.table ("./train/X_train.txt", header=FALSE, sep = "", col.names = features$V2)    # read in the training data and label the coloumn according to the list of features
train <- mutate(train, subject = trainLabel$V1)                                                 # add the Subjects column
testLabel <- read.table("./test/y_test.txt", header=FALSE, sep = " ")                           # this will create the list of the Subjects ID number that will eventuall become the subjects column in the data table
test <- read.table("./test/x_test.txt", header=FALSE, sep = "", col.names = features$V2)        # read in the training data and label the coloumn according to the list of features
test <- mutate(test, subject = testLabel$V1)                                                    # add the Subjects column
# Merges the training and the test sets to create one data set.
data <- bind_rows(train, test)          # this step merges the test and trainnig data sets
data <- tbl_df(data)                    # convert 'data' into a data a dplyr 'data frame tbl'
rm(test, testLabel, train, trainLabel)  # remove large tables that are not needed for futher analysis
# Extract only the measurements on the mean and standard deviation for each measurement.
meanCols <- which(grepl("mean", colnames(data)) == TRUE)        # identify the indices of the columnes that have the word "mean" somewhere in thier description
sdCols <- which(grepl("std", colnames(data)) == TRUE)           # identify the indices of the columnes that pertain to standard deviations and have "std" somewhere in thier description
data2 <- select(data, meanCols, sdCols, subject)                # subset of the original 'data' that only contains mean and standard deviation coloumns for each measurement
# From the data set in step 4, creates a second, independent
# tidy data set with the average of each variable for each activity and each subject.
data2 <- tbl_df(data2)                          # converts 'data2 into a data a dplyr 'data frame tbl'
data3 <-
data2 %>%
group_by(subject) %>%
summarise_each(funs(mean)) %>%          # calculate the mean of each column by subject
print
View(data3)                                     #view the outcome dataset
write.table(data3, file = "run_analysis_result.txt", row.name = FALSE)  #to submit to Coursera
